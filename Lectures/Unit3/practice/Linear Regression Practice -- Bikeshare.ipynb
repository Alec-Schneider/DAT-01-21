{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 12 Lab:  Linear Regression With the Bikeshare Dataset\n",
    "\n",
    "Welcome!  This notebook is designed to provide additional practice for people looking to get more familiar with Linear Regression and SciKit Learn.  \n",
    "\n",
    "The topic of the notebook is using Linear Regression to forecast demand for bikeshare stations.\n",
    "\n",
    "The dataset has the following columns:  \n",
    "\n",
    "  - **datetime:** a timestamp collected hourly.\n",
    "  - **season:** a categorical column that lists the current season for that observation\n",
    "  - **holiday:** a column (0 or 1), that detects whether or not it was a holiday\n",
    "  - **workingday:** a column (0 or 1), that encodes whether or not it was a workday or not\n",
    "  - **weather:** a categorical column that lists a light weather description for the observation\n",
    "  - **temp:** the temperature outside\n",
    "  - **atemp:** the temperature it feels like outside\n",
    "  - **humidity:** the humidity outside\n",
    "  - **windspeed:** the windspeed, in mph\n",
    "  - **count:** the number of bikes checked out during that hour\n",
    "  \n",
    "Your job is to build a regression model that appropriately captures the information available to make the most accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Load in the Dataset\n",
    "\n",
    " - It's called `bikeshare.csv`\n",
    " - Make sure to make `datetime` a time column\n",
    " - It's not a bad idea to use it as an index column, although this isn't necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Transform Your Categorical Variables (If Necessary)\n",
    "\n",
    "This dataset has two categorical columns -- `weather` and `season`.  Judging by their description, decide if they ought to be ordinal (contains a natural rank) or nominal (no natural rank).\n",
    "\n",
    "Remember -- ordinal variables can be encoded using increasing integer values.  Ie, `SM --> 1`, `Med --> 2`, `Large --> 3`, etc.\n",
    "\n",
    "Nominal variables should be one-hot encoded via `pd.get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a Training & Test Set\n",
    "\n",
    "Given that there's a time based column, make the most recent values your test set.  Do a 20% split.  (You can use `train_test_split` for this, but it's not really necessary.  You could also just sort by `datetime` and take the bottom 20% of rows for your test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a Validation Set From Your Training Set\n",
    "\n",
    "Remember....this is your test set within the training set.  Make it 20% of your training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Do An Initial Fitting And Scoring of Your Model\n",
    "\n",
    " - Remember, fit on the training set, and score on the validation set.\n",
    " - Standardize your data before fitting\n",
    " - How much is your model overfitting (if at all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer hereb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Look At Your Coefficients\n",
    "\n",
    "What seems to be having the most impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Build New Features (ie, Add New Columns To Your Dataset)\n",
    "\n",
    "This is your chance to think about ways to better capture the value and impact of time and other variables on the target variable (`count`).\n",
    "\n",
    "What you should do here is add a new feature to your training and validation set, re-run your model on the  training set, and score it on the validation set to see if it made an improvement.  \n",
    "\n",
    "A good place to start with this is extracting out different date parts to see if they improve your validation score.\n",
    "\n",
    "You can find information about the different dateparts in pandas here:  https://pandas.pydata.org/pandas-docs/version/0.24/reference/series.html#time-series-related\n",
    "\n",
    "Or if you're using the `datetime` column as an index:  https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html\n",
    "\n",
    "Keep features if they improve your validation score, discard them if they don't.\n",
    "\n",
    "A few other ideas:  you can create a column called `Daytime` that tests whether or not it's light outside.  (Ie, between 7PM - 6AM is `False`, `True` otherwise).  You could also get fancier and adjust the daylight hours depending on season.  \n",
    "\n",
    "You could also try multiplying different columns together.  Maybe it being `Daytime`, `Sunny` and low humidity has a multiplicative effect that isn't totally captured by any of the variables by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Score Your Model on the Test Set\n",
    "\n",
    "Once you've found the best version of your model on your validation set, transform your test set so that it is setup the same way.\n",
    "\n",
    "Ie, if you added a column that improved your validation score, add that same column to your test set.  \n",
    "\n",
    "Remember to standardize your test set using the values from your training set.\n",
    "\n",
    "How close were your validation scores to your test set scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics\n",
    "\n",
    "Now we'll look at a few different areas of your model to see if there's anything causing our results to be skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10:  Look at the values of the `count` column in your training set.  Are any of them unusually large?\n",
    "\n",
    "A histogram is a good way to visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11:  Make a prediction on your test set, and calculate the error\n",
    "\n",
    "The error in this case is just the difference between the value for `count` and the value of your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12:  Look at correlations between your error rates and the different columns in X.\n",
    "\n",
    "Is there anything that's systematically associated with your model making bad predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
